{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Bot Detection</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection and Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,glob,sys,nltk\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = 'Datasets'\n",
    "SRC_DIR = 'src'\n",
    "TWEETS_DIR = 'Tweets'\n",
    "BOT_TWEETS_DIR = 'Bot_accounts_tweets'\n",
    "GENUINE_TWEETS_DIR = 'Genuine_accounts_tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for organized printing only\n",
    "class txt_format:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Loading Data and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# genuine users => 0 , bots => 1\n",
    "cwd = os.getcwd()\n",
    "dataset_dir = os.path.join(cwd, DATASETS_DIR)\n",
    "os.chdir(dataset_dir)\n",
    "# Loading users data\n",
    "total_data = pd.DataFrame()\n",
    "for File_Name in glob.glob(\"*_users.csv\"):\n",
    "    df = pd.read_csv(File_Name)\n",
    "    if File_Name == 'genuine_accounts_users.csv':\n",
    "        df['bot'] = 0\n",
    "    elif File_Name == 'E13_users.csv' or File_Name == 'TFP_users.csv':\n",
    "        df['bot'] = 0\n",
    "        df['test_set_1'] = 0\n",
    "        df['test_set_2'] = 0\n",
    "    elif File_Name == 'fake_followers_users.csv':\n",
    "        df['bot'] = 1\n",
    "    elif 'social_spambots' in File_Name:\n",
    "        df['bot'] = 1\n",
    "    elif 'traditional_spambots' in File_Name:\n",
    "        df['bot'] = 1\n",
    "    else:\n",
    "        print(File_Name)\n",
    "    total_data = pd.concat([total_data,df], ignore_index = True, sort=False)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Loading Tweets and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'run_full_process' is a binary variable that decides wheather running all notebooks cells will take a few hours. If marked with 1, will run:\n",
    "* translation process using Yandex service - also limited by characters per day\n",
    "* language detection process using Yandex service - also limited by characters per day\n",
    "* BoW process\n",
    "* finding most important words in description text field\n",
    "* calculating the tweet features (not including the variation on Levenshtein distances. Takes some time)\n",
    "\n",
    "otherwise, will skip it and use pre-made files.\n",
    "\n",
    "'run_tweet_var_calculation' allows you to calculate the variance of Levenshtein Distance between tweets of a user. To do this, change value to 1. **Note:** This calculation takes hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_full_process = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tweet_var_calculation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_file_path = os.path.join(dataset_dir, 'tweet_features_filled1.csv')\n",
    "user_data = pd.read_csv(user_data_file_path)\n",
    "user_data.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_data_file_path = os.path.join(dataset_dir, 'tweet_var_data_full_with_threshold.csv')\n",
    "levenshtein_data = pd.read_csv(levenshtein_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_data_file_path = os.path.join(dataset_dir, 'description_data_set2.csv')\n",
    "description_df = pd.read_csv(description_data_file_path)\n",
    "if(run_full_process):\n",
    "    description_df = description_df[['Unnamed: 0', 'id', 'lang', 'description', 'bot','test_set_1', 'test_set_2']]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not run_full_process):\n",
    "    count_vectors_df = pd.DataFrame()\n",
    "    count_vectors_files_names = [file \n",
    "                                 for file in os.listdir(dataset_dir) \n",
    "                                 if os.path.isfile(os.path.join(dataset_dir, file)) and \n",
    "                                 'count_df_' in file\n",
    "                                ]\n",
    "    \n",
    "    for count_vectors_file_name in count_vectors_files_names:\n",
    "        count_vectors_data_file_path = os.path.join(dataset_dir, count_vectors_file_name)\n",
    "        count_df = pd.read_csv(count_vectors_data_file_path)\n",
    "        count_vectors_df = pd.concat([count_vectors_df,count_df], ignore_index = True)\n",
    "    count_vectors_df.drop('Unnamed: 0.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2.  Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_path = os.path.join(os.getcwd(),SRC_DIR)\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Data Undestanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding data types\n",
    "total_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training size:\n",
    "len(total_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # of basic user features (including target)\n",
    "total_data.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Perliminary Data Visualization and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.1. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.2. Language Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"-------------------------------\")\n",
    "print (\"Histogram for 'lang'\")\n",
    "print (\"-------------------------------\")\n",
    "print (total_data['lang'].value_counts())\n",
    "print (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Unique Values\n",
    "* id, screen_name are unique - **different value for each record**\n",
    "* contributors_enabled, follow_request_sent , following , notifications - **zero unique values** (NULL)\n",
    "* verified, protected, profile_use_background_image, profile_background_tile, is_translator, geo_enabled, default_profile, default_profile_image - **single unique value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns with zero unique values (NULL values only )\n",
    "* contributors_enabled \n",
    "* follow_request_sent \n",
    "* following \n",
    "* notifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in total_data.columns:\n",
    "    if total_data[col_name].nunique() < 1:\n",
    "        print('removing ', col_name)\n",
    "        total_data.drop(col_name, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing irrelevant columns : \n",
    "* dataset (dataset name) \n",
    "* crawled_at (date the data was crawled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop(['dataset','crawled_at'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. NULL Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing NULL count for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Missing_Values_Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import missingno as msno\n",
    "except ModuleNotFoundError as e:\n",
    "    !{sys.executable} -m pip install missingno --user\n",
    "    import missingno as msno       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph above, each number represents the non-null count for a certain column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.sum(total_data.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with more then 16,000 null values : \n",
    "* default_profile_image\n",
    "* is_translator\n",
    "* protected\n",
    "* verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 16000\n",
    "for col_name in total_data.columns:\n",
    "    if np.sum(total_data[col_name].isnull()) >= threshold:\n",
    "        print('removing ', col_name)\n",
    "        total_data.drop(col_name, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding the data type in each column, we replace the Nulls with the appropriate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing_Values_Lib.Fill_Missing(total_data)\n",
    "np.sum(np.sum(total_data.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a perliminary filling. More precise work will be done on feature engineering section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import General_Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following features are the numeric features from user data (before engineering)\n",
    "numeric_features_list = ['favourites_count',\n",
    "                 'followers_count',\n",
    "                 'friends_count',\n",
    "                 'listed_count',\n",
    "                 'statuses_count',\n",
    "                 'utc_offset',\n",
    "                 'bot']\n",
    "\n",
    "corr_mtx = General_Lib.Plot_Correlation_Matrix(total_data, numeric_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No apparent connection between main numeric features to the target**<br>\n",
    "**We can see there is a high correlation between:**\n",
    "1. listed_count - followers count \n",
    "2. listed_count - friends count \n",
    "3. friends count - followers count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mtx['bot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each numeric feature is binned in order to get better correlation with the target feature on the following section. Features getting the highest correlation will replace current used features and will be added to the list below for future use:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. favourites_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data[total_data.favourites_count<=150].favourites_count, bins = 10, kde = False)\n",
    "plt.title('Histogram of Favourites Count')\n",
    "plt.xlabel('Favourites')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'0' has the highest frequency. We'll bin binarily if the value is 0 or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['is_favourite'] = total_data['favourites_count'] > 0\n",
    "print(\"new feature - target correlation is:\",\n",
    "      total_data['is_favourite'].corr(total_data['bot']))\n",
    "print(\"old feature - target correlation is:\",\n",
    "        total_data['favourites_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('is_favourite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. followers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data[total_data.followers_count<=800].followers_count, bins = 20, kde = False)\n",
    "plt.title('Histogram of Followers Count')\n",
    "plt.xlabel('Followers')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_followers_count = total_data[total_data.followers_count<=300]\n",
    "df_count = pd.DataFrame({'bot_followers': df_followers_count[df_followers_count.bot==1].followers_count,\n",
    "                   'genuine_users_followers': df_followers_count[df_followers_count.bot==0].followers_count},\n",
    "                   columns=['bot_followers', 'genuine_users_followers'])\n",
    "plt.figure();\n",
    "df_count.plot.hist(title = 'Bot Followers vs. Genuine Users Followers (<300)',bins= 10,alpha=0.5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-target correlation:\",total_data['followers_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 5 equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_followers_count= General_Lib.Binning(total_data['followers_count'],5)\n",
    "print(\"Feature-target correlation:\",bin_followers_count.corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 5 <u>un</u>equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['bin_followers_count'] = General_Lib.Binning(total_data['followers_count'],\n",
    "                                                        -1, \n",
    "                                                        bin_seq = [0,12,20,30,100,np.inf])\n",
    "\n",
    "total_data.bin_followers_count = total_data.bin_followers_count.astype(int)\n",
    "print(\"Feature-target correlation:\",total_data['bin_followers_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We chose the bins by choosing the binning that maximizes the correlation to the target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "#only the following block yielding futureWraning beacuse of future change in scipy stats behavior (no way to fix it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data['bin_followers_count'], kde = False)\n",
    "plt.title('Histogram of Followers Count Binning')\n",
    "plt.xlabel('Followers Count Bins')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"always\", category=FutureWarning)  #restoring the default mode of warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('bin_followers_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. friends_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data[total_data.friends_count<=800].friends_count, bins = 20, kde = False)\n",
    "plt.title('Histogram of Friends Count')\n",
    "plt.xlabel('Friends')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_friends_count = total_data[total_data.friends_count<=500]\n",
    "df_count = pd.DataFrame({'bot_friends': df_friends_count[df_friends_count.bot==0].friends_count,\n",
    "                   'genuine_users_friends': df_friends_count[df_friends_count.bot==1].friends_count},\n",
    "                   columns=['bot_friends', 'genuine_users_friends'])\n",
    "plt.figure();\n",
    "df_count.plot.hist(title = 'Bot Friends vs. Genuine Users Friends (<800)',bins= 20,alpha=0.5)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-target correlation:\",total_data['friends_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 20 equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_friends_count = General_Lib.Binning(total_data['friends_count'],20)\n",
    "print(\"Feature-target correlation:\",bin_friends_count.corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 5 <u>un</u>equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['bin_friends_count'] = General_Lib.Binning(total_data['friends_count'],\n",
    "                                                      -1, \n",
    "                                                      bin_seq = [0,2,10,50,90,np.inf])\n",
    "print(\"Feature-target correlation:\",total_data['bin_friends_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['bin_friends_count'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('bin_friends_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. listed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data[total_data.listed_count<=10].listed_count, bins = 10, kde = False)\n",
    "plt.title('Histogram of Listed Count')\n",
    "plt.xlabel('Listed')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-target correlation:\",total_data['listed_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary binning if the value of listed_count feature is zero or not** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['is_listed_count'] = total_data['listed_count'] > 0\n",
    "print(\"Feature-target correlation:\",total_data['is_listed_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 5 equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_count_binning = General_Lib.Binning(total_data['listed_count'],8)\n",
    "print(\"Feature-target correlation:\",listed_count_binning.corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 8 <u>un</u>equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['listed_count_binning'] = General_Lib.Binning(total_data['listed_count'],\n",
    "                                                         -1, \n",
    "                                                         bin_seq = [0,2,10,50,200,300,500,1000,np.inf])\n",
    "total_data.listed_count_binning = total_data.listed_count_binning.astype(int)\n",
    "print(\"Feature-target correlation:\",total_data['listed_count_binning'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('is_listed_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. statuses_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data[total_data.statuses_count<=500].statuses_count, bins = 10, kde = False)\n",
    "plt.title('Histogram of Statuses Count')\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-target correlation:\",total_data['statuses_count'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 3 unequal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['statuses_count_binning'] = General_Lib.Binning(total_data['statuses_count'],\n",
    "                                                           -1, \n",
    "                                                           bin_seq = [0,80,300, np.inf])\n",
    "total_data.statuses_count_binning = total_data.statuses_count_binning.astype(int)\n",
    "print(\"Feature-target correlation:\",total_data['statuses_count_binning'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 50 equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses_count_binning = General_Lib.Binning(total_data['statuses_count'],50)\n",
    "print(\"Feature-target correlation:\",statuses_count_binning.corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see binning 3 buckets has given us great correlation to the target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('statuses_count_binning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6. utc_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(total_data[total_data.utc_offset<=20000].utc_offset, bins = 10, kde = False)\n",
    "plt.title('Histogram of Utc Count')\n",
    "plt.xlabel('utc')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utc_offset = total_data[total_data.utc_offset<=20000]\n",
    "df_count = pd.DataFrame({'bot_utc_offset': df_utc_offset[df_utc_offset.bot==0].utc_offset,\n",
    "                   'genuine_users_utc_offset': df_utc_offset[df_utc_offset.bot==1].utc_offset},\n",
    "                   columns=['bot_utc_offset', 'genuine_users_utc_offset'])\n",
    "plt.figure();\n",
    "df_count.plot.hist(title = 'Bot UTC vs. Genuine Users UTC (<20000)',bins= 20,alpha=0.5)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-target correlation:\",total_data['utc_offset'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 20 equal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_offset_binning_1 = General_Lib.Binning(total_data['utc_offset'],20)\n",
    "print(\"Feature-target correlation:\",utc_offset_binning_1.corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning to 3 uequal width buckets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_offset_binning_2 = General_Lib.Binning(total_data['utc_offset'],\n",
    "                                           -1, \n",
    "                                           bin_seq = [-30000, 0, 10000, 20000])\n",
    "print(\"Feature-target correlation:\",utc_offset_binning_2.corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary binning if utc_offset is greater than zero or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['is_utc_offset'] = total_data['utc_offset'] > 0\n",
    "print(\"Feature-target correlation:\",total_data['is_utc_offset'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary binning has provided the best correlation to the target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('is_utc_offset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7. New Numeric Features Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of high correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numeric_features.append('bot')\n",
    "corr_mtx = General_Lib.Plot_Correlation_Matrix(total_data, new_numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mtx['bot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Date and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time and date features:** \n",
    "* created_at\n",
    "* timestamp \n",
    "* updated \n",
    "\n",
    "We'll parse time and dates features to int features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Date_Parser_Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. created_at feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created_at feature contains two date formats:\n",
    "1. Day Month Day_in_month Hour:Minute:Seconds Time zone Year.\n",
    " * For example: Wed Jul 04 12:30:03 +0000 2007\n",
    "2. Seconds from epoch\n",
    " * For example: 1183552203000L\n",
    "\n",
    "**We will parse seconds from epoch format to the format described in bullet number 1. <br>\n",
    "Then we will parse the updated feature to create new 7 numeric features:**\n",
    "1. day of the week\n",
    "2. month\n",
    "3. day in month\n",
    "4. hour\n",
    "5. minute\n",
    "6. second\n",
    "7. year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'created_at'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check_For_Date_Format:** analyze the feature date format. <br>\n",
    "<u>Return value: </u>\n",
    "* seconds_from_epoch_data - samples contains seconds from epoch date format. <br>\n",
    "* regular_date_format_data - all the remains samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seconds_from_epoch_data,regular_date_format_data = Date_Parser_Lib.Check_For_Date_Format(total_data, \n",
    "                                                                                         feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  parse seconds from epoch date format \n",
    "* ignoring time zone (+0000 on every row).\n",
    "* Convert seconds from epoch to regular date format\n",
    "* Example of seconds from epoch date format: 1183552203000L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seconds_from_epoch_data['created_at'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert seconds from epoch date format to regular format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_format_ceated_at = '%a %b %d %H:%M:%S +0000 %Y'\n",
    "seconds_from_epoch_data[feature_name] = seconds_from_epoch_data[feature_name].apply(\n",
    "                                        Date_Parser_Lib.convert_seconds_from_epoch_to_date_format,\n",
    "                                        args = (date_format_ceated_at,))\n",
    "\n",
    "seconds_from_epoch_data['created_at'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate the records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat([seconds_from_epoch_data,regular_date_format_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**validate there is'nt any seconds from epoch format **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_Parser_Lib.Rows_Contain_Seconds_From_Epoch_Format(total_data,feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse created_at column to create new numeric features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_names,features_corr = Date_Parser_Lib.Parse_Feature_and_Print_Corr(total_data, \n",
    "                                                                  feature_name, \n",
    "                                                                  'bot', \n",
    "                                                                  date_format_ceated_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New features correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr['bot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **we cannot rely on the created year, as new bots created  all the time.**<br>\n",
    "* **we will check the created_at_month feature<br>**\n",
    " * We assume maybe there is a connection between the created month to bot accounts <br>\n",
    "* **There isn't a distinct connection between all the remains new features to the target feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data[total_data['bot']==1]['created_at_month'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data[total_data['bot']==0]['created_at_month'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**February and March months are the most frequent months for bot accounts creation** <br>\n",
    "**Binning according to those months**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['is_february_march'] = (total_data['created_at_month'] == 2) | (total_data['created_at_month'] == 3)\n",
    "print(\"Feature-target correlation:\",total_data['is_february_march'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binning according to top 4 months for bot accounts creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bot_months = [1,2,3,6]\n",
    "total_data['is_top_month'] = total_data.apply(lambda x: \n",
    "                                              1 if x['created_at_month'] in top_bot_months \n",
    "                                              else 0,\n",
    "                                             axis = 1)\n",
    "print(\"Feature-target correlation:\",total_data['is_top_month'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We managed to create new feature with correlation a little higher from the month feature. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove created_at feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop([feature_name], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Updated column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This column was added by the researchers and it is the same value at each dataset file.<br> \n",
    "We will remove this feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop(['updated'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. timestamp column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This column was added by the researchers and isn't part of twitter's API.<br> \n",
    "We will remove this feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop(['timestamp'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Textual User Features (without description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We devided the text features to 3 groups:\n",
    "* Color features\n",
    "* Location feature\n",
    "* General text features\n",
    "\n",
    "each group was treated in a slightly different way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Features List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_types = total_data.columns.to_series().groupby(df.dtypes).groups\n",
    "str_cols_names = [v \n",
    "                  for k, v in groups_types.items() \n",
    "                  if k.name == 'object'][0]\n",
    "\n",
    "if 'profile_text_color' not in str_cols_names:\n",
    "    str_cols_names = str_cols_names.append(pd.Index(['profile_text_color']))\n",
    "\n",
    "print('{0}{1}{2}{3}{3}'.format(txt_format.BOLD,\n",
    "                               txt_format.UNDERLINE,\n",
    "                               'Text features:',\n",
    "                               txt_format.END))\n",
    "\n",
    "for col_name in str_cols_names:\n",
    "    print(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. General Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each general text feature we added 5 new numeric features:\n",
    "* <u>Replace a string with unique value:</u> \n",
    "  * defined unique mapping from feature values to int and apply to the feature values.\n",
    "* <u>Replace missing values by unique mapping by mode:</u>  \n",
    "  * For the features created by the unique values, there are missing values (marked as enpty string). We will replace those values by mode. \n",
    "  * We split the mode replacement to two options: \n",
    "   * If all the nan values is of bot account: replace the missing values by the bot mode value of the feature.    \n",
    "   * else replace by feature mode. \n",
    "* <u>Replace missing values by unique mapping by distribution:</u> \n",
    " * same as for the mode case, only we replace the missing values from feature distribution. \n",
    "* <u>Binning by is most common:</u>  \n",
    " * For features we detected a single value that is the most common value, we created a new feature indicating if the sample contains the most common value or not.  \n",
    "* <u>Replace a string with length:</u>\n",
    " * Replace each string with it's length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Text_Features_Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Detect if all missing values is of bot account.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Is_All_Nan_of_Bot(df, feature_name):\n",
    "    bot_nan_num = np.sum(df[df['bot'] == 1][feature_name]=='') \n",
    "    if bot_nan_num == 0:\n",
    "        return False\n",
    "    return np.sum(df[feature_name]=='') == bot_nan_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**most common values dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_most_common_values = {\n",
    "    'lang': 'en',\n",
    "    'time_zone': '',\n",
    "    'profile_banner_url': '',\n",
    "    'profile_background_image_url': 'http://a0.twimg.com/images/themes/theme1/bg.png',\n",
    "    'profile_background_image_url_https': 'https://si0.twimg.com/images/themes/theme1/bg.png',\n",
    "    'profile_background_color': 'C0DEED',\n",
    "    'profile_link_color': '0084B4',\n",
    "    'profile_sidebar_border_color': 'C0DEED',\n",
    "    'profile_sidebar_fill_color': 'DDEEF6',\n",
    "    'profile_text_color':'333333',\n",
    "    'url': 'https://t.co/DByWt45HZj'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General features list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_txt_features = [feature \n",
    "                for feature in str_cols_names \n",
    "                if 'color' not in feature\n",
    "                 and feature != 'description']\n",
    "for feature in g_txt_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop('description', axis = 1, inplace = True)\n",
    "str_cols_names = str_cols_names.drop('description')\n",
    "\n",
    "for feature_name in g_txt_features:\n",
    "    use_bot_mode = Is_All_Nan_of_Bot(total_data, feature_name)\n",
    "    \n",
    "    if feature_name == 'lang':\n",
    "        #unite same lang\n",
    "        total_data[feature_name] = total_data[feature_name].str.lower()\n",
    "    \n",
    "    Text_Features_Lib.Add_Numeric_Features_From_Str(total_data, \n",
    "                                                    feature_name, \n",
    "                                                    features_most_common_values, \n",
    "                                                    use_bot_mode)\n",
    "    \n",
    "    if feature_name != 'location':\n",
    "        total_data.drop(feature_name, axis = 1, inplace = True)\n",
    "        str_cols_names = str_cols_names.drop(feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. Location Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created locations binning for the this feature, and assigned each location a unique number.\n",
    "The bins were chosen by frequency of appearances of locations - U.S, Italy, Europe w.o Italy, Asia+Oceania , Nan and the rest of the world  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Location_Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['location_binning'] = total_data['location'].apply(Location_Lib.checkCountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-target correlation:\",total_data['location_binning'].corr(total_data['bot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop('location', axis = 1, inplace = True)\n",
    "str_cols_names = str_cols_names.drop('location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Color Features\n",
    "For each color feature we added 10 new numeric features:\n",
    "* Creating 4 general numeric features from text features (mentioned on 3.3.1), except for the length feature\n",
    " * The color features contains 6 characters, hence the legth feature is meaningless.\n",
    "* <u> Binning by main colors: </u>\n",
    " * We defined 12 main colors: black, white, blue, red, green, pink, brown, purple, grey, yellow, orange, turquoise. We mapped the main colors to int values. We performed the binning by calculating the nearest color (defined as the color with the minimum distance to the current color). \n",
    "* <u>Replace missing values in color binning by mode:</u>  \n",
    " * Same as in the general case\n",
    "* <u>Replace missing values in color binning by distribution:</u>  \n",
    " * Same as in the general case\n",
    "* <u> Binning by top 3 colors: </u>\n",
    " * After binning by main colors, we will perform more specific binning to top 3 colors only for each feature. The top 3 colors does not include the nan values, hence the total binning if of four colors (0 for the missing values). \n",
    "   * We tested several options for the top colors number, and discovered that 3 is the most effective number to choose. \n",
    "* <u>Replace missing values in top color binning by mode:</u>  \n",
    " * Same as in the general case\n",
    "* <u>Replace missing values in top color binning by distribution:</u> \n",
    " * Same as in the general case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Color_Features_Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main colors dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_colors = {\n",
    "    (0,0,0): 1, # black\n",
    "    (255,255,255): 2, # white\n",
    "    (0,0,255): 3, # blue\n",
    "    (255,0,0): 4, # red\n",
    "    (0,255,0): 5, # green\n",
    "    (255,192,203): 6, # pink\n",
    "    (165,42,42): 7, # brown\n",
    "    (128,0,128): 8, # purple\n",
    "    (128,128,128): 9, # grey\n",
    "    (255,255,0): 10, # yellow\n",
    "    (255,165,0): 11, # orange\n",
    "    (64,224,208): 12 # Turquoise\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Color_Features_Lib.main_colors = main_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Color features list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_features = [feature for feature in str_cols_names if 'color' in feature]\n",
    "for feature in color_features: \n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in color_features:\n",
    "    \n",
    "    apply_str = False\n",
    "    if feature_name == 'profile_link_color':\n",
    "        apply_str = True\n",
    "        \n",
    "    Color_Features_Lib.Prepare_Color_Features(total_data, \n",
    "                                              feature_name, \n",
    "                                              features_most_common_values, \n",
    "                                              apply_str)\n",
    "    \n",
    "    total_data.drop(feature_name, axis = 1, inplace = True)\n",
    "    str_cols_names = str_cols_names.drop(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(str_cols_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All text features have been parsed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between new features to bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key,value) in Text_Features_Lib.correlation_dict.items():\n",
    "    print('{0}{1}{2}{3}{3}'.format(txt_format.BOLD,\n",
    "                                   txt_format.UNDERLINE,\n",
    "                                   key,\n",
    "                                   txt_format.END))\n",
    "    \n",
    "    for (sub_key,sub_value) in value.items():\n",
    "        print('{0} : {1}'.format(sub_key,sub_value))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Tweet Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following blocks in comment describe how tweet_features_filled1.csv and tweet_var_data_full_with_threshold.csv were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tweet_Features_Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculation of tweets var and the range var feature, change 'run_tweet_var_calculation' from the begining of the notebook parameter to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating tweet_var and 500<var<750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_tweet_var_calculation: #data is read in the functions\n",
    "    Tweet_Features_Lib.generate_all_tweets_datasets(DATASETS_DIR,TWEETS_DIR,\n",
    "                                                   GENUINE_TWEETS_DIR,BOT_TWEETS_DIR)\n",
    "    print('done generating files')\n",
    "    tweet_var_df = Tweet_Features_Lib.run_tweet_var_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Tweets Data - for tweet-metadata features calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_full_process:\n",
    "    import Tweet_Features_Lib\n",
    "    ### loading the tweet data\n",
    "    tweet_data = pd.DataFrame()\n",
    "    tweets_dir =  os.path.join(os.getcwd(), DATASETS_DIR, TWEETS_DIR)\n",
    "    genuine_tweets_files,bot_tweets_files = Tweet_Features_Lib.get_tweets_files_names(DATASETS_DIR, \n",
    "                                                                                      TWEETS_DIR, \n",
    "                                                                                      GENUINE_TWEETS_DIR, \n",
    "                                                                                      BOT_TWEETS_DIR\n",
    "                                                                                     )\n",
    "    \n",
    "    \n",
    "    \n",
    "    genuine_tweets_files = [os.path.join(tweets_dir, GENUINE_TWEETS_DIR, file)\n",
    "                           for file in genuine_tweets_files]   \n",
    "    \n",
    "    \n",
    "    bot_tweets_files = [os.path.join(tweets_dir, BOT_TWEETS_DIR, file)\n",
    "                           for file in bot_tweets_files] \n",
    "    \n",
    "    tweets_datasets = bot_tweets_files + genuine_tweets_files\n",
    "    for file_name in tweets_datasets:\n",
    "        print('loading ' + file_name)\n",
    "\n",
    "\n",
    "        df_t = pd.read_csv(file_name, usecols=['id','text','user_id','retweet_count',\n",
    "                                             'favorite_count','num_hashtags','num_urls',\n",
    "                                             'num_mentions','created_at'],\n",
    "                        dtype={'id':str,'text':str,'user_is':str,'retweet_count':float,\n",
    "                              'favorite_count':float,'num_hashtags':float,'num_urls':float,\n",
    "                               'num_mentions':float,'created_at':str})\n",
    "        \n",
    "        if 'traditional_spambots_1_tweets_' in file_name:\n",
    "            temp_date = df_t['created_at'].apply(Date_Parser_Lib.convert_seconds_from_epoch_to_date_format,\n",
    "                                               args = (date_format_ceated_at,))\n",
    "            df_t['created_at'] = pd.to_datetime(temp_date)\n",
    "        else:\n",
    "            df_t['created_at'] = pd.to_datetime(df_t['created_at'])\n",
    "        \n",
    "        if 'genuine' in file_name or 'E13' in file_name or 'TFP' in file_name: \n",
    "            df_t['bot'] = 0\n",
    "        else:\n",
    "            df_t['bot'] = 1\n",
    "        tweet_data = pd.concat([tweet_data,df_t], ignore_index = True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating features based on tweet metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_full_process:\n",
    "    ### check for nulls\n",
    "    null_columns=tweet_data.columns[tweet_data.isnull().any()]\n",
    "    tweet_data[null_columns].isnull().sum()\n",
    "\n",
    "    ##remove tweets with no text\n",
    "    tweet_data.dropna(subset=['text'],inplace=True)\n",
    "\n",
    "    ##fill nan favorite count with 0\n",
    "    tweet_data.fillna(value={'favorite_count':0},inplace=True)\n",
    "\n",
    "    ### adding the proportion featres\n",
    "    user_data_partial = Tweet_Features_Lib.calc_prop_tweet_features(tweet_data)\n",
    "    user_data_partial.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**since not all users in the dataset have tweets, we fill the nulls with the mean values of the correct type: human users get the mean values for humans and bots get the mean values for bots (done for each new feature). \n",
    "In the following brackets the mean values are computed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_full_process:\n",
    "    ### we want to fill nulls with mean according to bot/human:\n",
    "    human_data = user_data_partial[user_data_partial['bot']==0].copy()\n",
    "    bot_data = user_data_partial[user_data_partial['bot']==1].copy()\n",
    "    #droping nulls\n",
    "    cols = ['p_retweet','p_favorites','p_hashtags','p_urls','p_mentions','avg_tweets_per_hour']\n",
    "    human_data.dropna(subset=cols,inplace=True)\n",
    "    bot_data.dropna(subset=cols,inplace=True)\n",
    "\n",
    "    #these will contain the maen value of each column\n",
    "    human_dict = {}\n",
    "    bot_dict = {}\n",
    "    for col in cols:\n",
    "        human_dict[col]=human_data[col].mean()\n",
    "        bot_dict[col]=bot_data[col].mean()\n",
    "    \n",
    "    ### merge with total data\n",
    "    temp_total = pd.merge(user_data_partial,total_data, how = 'outer')\n",
    "    temp_total.dropna(subset=['id'], inplace=True) #remove lines without id, if exist\n",
    "    np.sum(temp_total.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fill nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_full_process:\n",
    "    ### filling nulls and saving\n",
    "    human_data = temp_total[temp_total['bot']==0].copy()\n",
    "    bot_data = temp_total[temp_total['bot']==1].copy()\n",
    "    human_data.fillna(human_dict,inplace=True)\n",
    "    bot_data.fillna(bot_dict,inplace=True)\n",
    "    tot = pd.concat([human_data,bot_data],ignore_index=True)\n",
    "    features=['id','p_retweet','p_favorites','p_hashtags','p_urls','p_mentions','avg_tweets_per_hour']\n",
    "    tot.to_csv('tweet_features_filled.csv',columns=features) #add Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenshtein_data = levenshtein_data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after filling with mean\n",
    "df_tweet_var = pd.DataFrame({'bot_tweet_var':levenshtein_data[levenshtein_data.bot==1].tweet_var,\n",
    "                             'genuine_users_tweet_var': levenshtein_data[levenshtein_data.bot==0].tweet_var})\n",
    "plt.figure()\n",
    "df_tweet_var.plot.hist(title='Bot vs. Genuine Users Aerage Variation in Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Tweet Variance for Human Users and the Bot Users Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trad_samp_file = os.path.join(DATASETS_DIR,'traditional_spambots_1_sample_lev.csv')\n",
    "trad_samp = pd.read_csv(trad_samp_file, usecols=['id','tweet_var'])\n",
    "\n",
    "soc1_samp_file = os.path.join(DATASETS_DIR,'social_spambots_1_sample_lev.csv')\n",
    "soc1_samp = pd.read_csv(soc1_samp_file, usecols=['id','tweet_var'])\n",
    "\n",
    "soc2_samp_file = os.path.join(DATASETS_DIR,'social_spambots_2_sample_lev.csv')\n",
    "soc2_samp = pd.read_csv(soc2_samp_file, usecols=['id','tweet_var'])\n",
    "\n",
    "soc3_samp_file = os.path.join(DATASETS_DIR,'social_spambots_3_sample_lev.csv')\n",
    "soc3_samp = pd.read_csv('Datasets/social_spambots_3_sample_lev.csv', usecols=['id','tweet_var'])\n",
    "\n",
    "fake_samp_file = os.path.join(DATASETS_DIR,'fake_followers_sample_lev.csv')\n",
    "fake_samp = pd.read_csv(fake_samp_file, usecols=['id','tweet_var'])\n",
    "\n",
    "human_samp_file = os.path.join(DATASETS_DIR,'human_100_frac0.1_lev.csv')\n",
    "human_samp = pd.read_csv(human_samp_file, usecols=['id','tweet_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "trad_samp['tweet_var'].plot.hist(title='Variation in Tweets in Spambots')\n",
    "fake_samp['tweet_var'].plot.hist()\n",
    "soc1_samp['tweet_var'].plot.hist()\n",
    "soc2_samp['tweet_var'].plot.hist()\n",
    "soc3_samp['tweet_var'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the diagram above, most of the bot are out of the range 500 and 750 (roughly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**statistical information of each bot type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('traditional spambots 1:')\n",
    "print(trad_samp['tweet_var'].describe())\n",
    "print(' ')\n",
    "print('fake followers:')\n",
    "fake_samp['tweet_var'].describe()\n",
    "print(' ')\n",
    "print('social spambots 1:')\n",
    "print(soc1_samp['tweet_var'].describe())\n",
    "print(' ')\n",
    "print('social spambots 2:')\n",
    "print(soc2_samp['tweet_var'].describe())\n",
    "print(' ')\n",
    "print('social spambots 3:')\n",
    "print(soc3_samp['tweet_var'].describe())\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "human_samp['tweet_var'].plot.hist(title='Variation in Tweets in Genuine Users')\n",
    "human_samp['tweet_var'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding tweet features to the total data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.merge(user_data,total_data, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.merge(levenshtein_data,total_data, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = total_data.dropna(subset=['id'])\n",
    "if 'bot' in total_data.columns or 'tweet_var' in total_data.columns:\n",
    "    total_data = total_data.dropna(subset=['bot','tweet_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_features = ['p_retweet','p_favorites','p_hashtags','p_urls','p_mentions','avg_tweets_per_hour','500<var<750']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets - Target Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mtx = General_Lib.Plot_Correlation_Matrix(total_data, tweet_features + ['bot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mtx['bot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_features_for_models = ['p_hashtags','p_mentions','500<var<750']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, p_hashtags,p_mentions and 500<var<750 are higly correlated to our target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Description Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling 'description' field created the need to translate descriptions to English in order to create BoW - a character limited process . In addition, a long preprocessing process was used in dictionary creation, and running it takes a long time.\n",
    "Therefore in some sections below we used the 'run_full_process' variable, in order to control running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from yandex.Translater import Translater\n",
    "except ModuleNotFoundError as e:\n",
    "    #see if need user flag in university\n",
    "    !{sys.executable} -m pip install yandex-translater --user \n",
    "\n",
    "try:\n",
    "    from textblob import TextBlob, Word\n",
    "except ModuleNotFoundError as e:\n",
    "    !{sys.executable} -m pip install textblob --user\n",
    "    \n",
    "try:\n",
    "    import nltk\n",
    "except ModuleNotFoundError as e:\n",
    "    !{sys.executable} -m pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(run_full_process):\n",
    "    \n",
    "    nltk.download('punkt')\n",
    "    nltk.download('wordnet')\n",
    "    # # # # translating description # # # # #\n",
    "    description_df = Description.description_trans(description_df)\n",
    "    # # # # detect language # # # # #\n",
    "    description_df = Description.add_language_detection(description_df)\n",
    "    # # # # creating BoW and extracting most important words from it# # # # #\n",
    "    count_vectors_df, important_words = Description.find_important_words_from_bow(description_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.5.1. Description Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description data includes original description column, translated description ('translation') and language detection ('description_lang'). We uploaded it, removed unnecessary columns added in csv creation and filled NA with empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in description_df.columns:\n",
    "    description_df = description_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['description'].fillna('', inplace = True)\n",
    "description_df['translation'].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2. Count Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count vectors data frame includes count of each word in each description (each column is a word in the dictionary). In this section we removed unnecessary column that was created while exporting to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in count_vectors_df.columns:\n",
    "    count_vectors_df = count_vectors_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3. Extracting Features From Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetures extracted from description are:\n",
    "\n",
    "* Count Number of Words In a Description\n",
    "* Count Number of characters In a Description\n",
    "* Find Average Word Length in a Description\n",
    "* Count Number of Stopwords in a Description\n",
    "* Count Number of Hashtags in a Description\n",
    "* Count Number of Numerics in a Description\n",
    "* Count Number of Uppercase Words in a Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    if(len(words) == 0):\n",
    "        return 0\n",
    "    return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['word_count'] = description_df['description'].apply(lambda x: len(str(x).split(\" \")))\n",
    "description_df['char_count'] = description_df['description'].str.len() ## this also includes spaces\n",
    "description_df['avg_word'] = description_df['description'].apply(lambda x: avg_word(x))\n",
    "description_df['stopwords'] = description_df['translation'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "description_df['hashtags'] = description_df['description'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "description_df['numerics'] = description_df['description'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "description_df['upper'] = description_df['translation'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "description_df[['translation','word_count','char_count','avg_word','stopwords','hashtags','numerics','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important words is a list of 10 most important wotds that were extracted from BoW process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words = ['job','lover','love','student','life','follow','instagram','thing','italy','live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words_df = count_vectors_df[np.concatenate((['main_id'], important_words), axis=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging word count vectors with basic description features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = description_df.merge(important_words_df, left_on=\"id\",right_on=\"main_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df.drop([\"main_id\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = description_df.rename(index=str, columns={\"job\": \"job_appearances\", \"lover\": \"lover_appearances\", \"love\": \"love_appearances\",\n",
    "                                          \"student\": \"student_appearances\", \"life\": \"life_appearances\", \"follow\": \"follow_appearances\",\n",
    "                                          \"instagram\": \"instagram_appearances\", \"thing\": \"thing_appearances\",\"italy\": \"italy_appearances\", \n",
    "                                          \"live\": \"live_appearances\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 'contains_url'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 'http' appeared in a description we mared a description as one that containes a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectors_df['http'] = count_vectors_df['http'].reset_index(drop=True)\n",
    "description_df['contains_url'] = 0\n",
    "description_df['contains_url'] = description_df['contains_url'].reset_index(drop=True)\n",
    "count_vectors_df['http'].index = description_df['contains_url'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['contains_url'] = count_vectors_df['http'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['contains_url'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Language Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'description_lang' which was added to 'description_df' with Yandex service of language detection. If 'description_lang' is different from an account's language ('lang') it was marked with '1', otherwise '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['different_lang'] = description_df['description_lang'] == description_df['lang']\n",
    "description_df['different_lang'] = description_df['different_lang'].apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['different_lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4. Description Features Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Pearson Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_for_correlation = ['word_count','char_count','avg_word','stopwords','hashtags','numerics',\n",
    "                        'upper','job_appearances','lover_appearances','love_appearances',\n",
    "                        'student_appearances','life_appearances', 'follow_appearances', 'instagram_appearances',\n",
    "                        'thing_appearances', 'italy_appearances', 'live_appearances', 'contains_url',\n",
    "                        'different_lang','bot']\n",
    "\n",
    "corr_mtx = General_Lib.Plot_Correlation_Matrix(description_df,features_for_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mtx['bot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Features Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of spambots containing the word 'job' is\"\n",
    "      ,description_df[description_df.bot==1]['job_appearances'].apply(lambda x: 1 if x > 0 else 0).sum() ,\n",
    "      \"and number of genuine accounts containing 'job' is\",\n",
    "      description_df[description_df.bot==0]['job_appearances'].apply(lambda x: 1 if x > 0 else 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of spambots containing the word 'follow' is\",\n",
    "      description_df[description_df.bot==1]['follow_appearances'].apply(lambda x: 1 if x > 0 else 0).sum() ,\n",
    "      \"and number of genuine accounts containing 'follow' is\",\n",
    "      description_df[description_df.bot==0]['follow_appearances'].apply(lambda x: 1 if x > 0 else 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of accounts with different language than declared is:\", description_df[description_df.bot==0]['different_lang'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Final Description Features with Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_features = ['id','word_count','char_count','avg_word','stopwords','hashtags','numerics',\n",
    "                        'upper','job_appearances','lover_appearances','love_appearances',\n",
    "                        'student_appearances','life_appearances', 'follow_appearances', 'instagram_appearances',\n",
    "                        'thing_appearances', 'italy_appearances', 'live_appearances', 'contains_url', 'different_lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_features_for_model = ['word_count','avg_word','stopwords','job_appearances','follow_appearances','different_lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df[description_features].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.merge(description_df[description_features],total_data, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Visualization & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most visualization work is done on each part above**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the section below we choose user features with the highest correlation to target. For tweets and description features we chose high correlated features above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target - Feature Correlations: User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['pearson', 'kendall', 'spearman']\n",
    "features_list_to_drop = tweet_features + description_features + ['bot']\n",
    "General_Lib.Print_Target_Features_Correlation(total_data, \n",
    "                                              methods, \n",
    "                                              'bot', \n",
    "                                              features_list_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_base_correlated_features = ['is_favourite', \n",
    "                                'statuses_count_binning',\n",
    "                                'bin_followers_count', \n",
    "                                'profile_background_color_unique_dist',\n",
    "                                'is_utc_offset',\n",
    "                                'is_top_month',\n",
    "                                'geo_enabled',\n",
    "                                'time_zone_most_common',\n",
    "                                'profile_banner_url_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features_to_use = top_base_correlated_features + tweet_features_for_models + description_features_for_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing data by binary columns 'test_set_1' (we use it as validation set) and 'test_set_2' (we use it by test set). When marked with '1' an account belongs to a test set, otherwise, belongs to training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_set_1, test_set_2 = General_Lib.train_test_division(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing train data into X values and y values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = train_data['bot']\n",
    "x_train = train_data[total_features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "DTclassifier = DecisionTreeClassifier(criterion='entropy', class_weight = {0:1,1:2})  \n",
    "DTclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFclassifier = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "RFclassifier.fit(x_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(RFclassifier.feature_importances_,\n",
    "                                   index = x_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Logistic Resression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LRclassifier = LogisticRegression(solver='liblinear')\n",
    "LRclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRclassifier.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Evaluation_Results_Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing validation and test data into X values and y values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = test_set_1['bot']\n",
    "x_validation = test_set_1[total_features_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_set_2['bot']\n",
    "x_test = test_set_2[total_features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_descisionTree = DTclassifier.predict(x_validation)  \n",
    "y_pred_descisionTree_probs = DTclassifier.predict_proba(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_validation, \n",
    "                                     y_pred_descisionTree,  \n",
    "                                     classifier_name = 'Decision_Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_descisionTree_test = DTclassifier.predict(x_test)  \n",
    "y_pred_descisionTree_probs_test = DTclassifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_test, \n",
    "                                     y_pred_descisionTree_test, \n",
    "                                     classifier_name = 'Decision_Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "y_pred_forest = RFclassifier.predict(x_validation)\n",
    "y_pred_forest_probs = y_pred_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forest = y_pred_forest >=0.5\n",
    "y_pred_forest = y_pred_forest.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_validation, \n",
    "                                     y_pred_forest, \n",
    "                                     classifier_name = 'Random_Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "y_pred_forest_test = RFclassifier.predict(x_test)\n",
    "y_pred_forest_probs_test = y_pred_forest_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forest_test = y_pred_forest_test >=0.5\n",
    "y_pred_forest_test = y_pred_forest_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_test, \n",
    "                                     y_pred_forest_test,  \n",
    "                                     classifier_name = 'Random_Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = LRclassifier.predict(x_validation)\n",
    "y_pred_lr_probs = LRclassifier.predict_proba(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_validation, \n",
    "                                     y_pred_lr, \n",
    "                                     classifier_name = 'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_test = LRclassifier.predict(x_test)\n",
    "y_pred_lr_probs_test = LRclassifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_test, \n",
    "                                     y_pred_lr_test, \n",
    "                                     classifier_name = 'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Collective Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model classifies by the majority in all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {'Decision_Trees':y_pred_descisionTree, \n",
    "            'Random_Forest':y_pred_forest,\n",
    "            'LG':y_pred_lr\n",
    "           }\n",
    "\n",
    "results = pd.DataFrame(data = res_dict)\n",
    "results['Collective_Model'] = results.mode(axis = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_validation, \n",
    "                                     results['Collective_Model'],  \n",
    "                                     classifier_name = 'Collective_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_test = {'Decision_Trees':y_pred_descisionTree_test, \n",
    "                 'Random_Forest':y_pred_forest_test,\n",
    "                 'LG':y_pred_lr_test\n",
    "                }\n",
    "\n",
    "results_test = pd.DataFrame(data = res_dict_test)\n",
    "results_test['Collective_Model'] = results_test.mode(axis = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.print_results(y_test, \n",
    "                                     results_test['Collective_Model'],  \n",
    "                                     classifier_name = 'Collective_Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. ROC\\AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1 Validation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.Plot_Metrics(y_validation,\n",
    "                                    y_pred_descisionTree_probs[:,1], \n",
    "                                    'Descision_Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.Plot_Metrics(y_validation,\n",
    "                                    y_pred_forest_probs, \n",
    "                                    'Random_Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.Plot_Metrics(y_validation,\n",
    "                                    y_pred_lr_probs[:,1], \n",
    "                                    'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2. Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.Plot_Metrics(y_test,\n",
    "                                    y_pred_descisionTree_probs_test[:,1], \n",
    "                                    'Descision_Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.Plot_Metrics(y_test,\n",
    "                                    y_pred_forest_probs_test, \n",
    "                                    'Random_Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Evaluation_Results_Lib.Plot_Metrics(y_test,\n",
    "                                    y_pred_lr_probs_test[:,1], \n",
    "                                    'Logistic_Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6. Robustness Test : K-Fold For the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation with the model that yields the best results : **Collective Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle = True)\n",
    "rfc = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "lrc = LogisticRegression(solver='liblinear')\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', class_weight = {0:1,1:2})\n",
    "for train_indices, test_indices in kfold.split(x_train):\n",
    "    rfc.fit(x_train.iloc[train_indices], y_train.iloc[train_indices])\n",
    "    lrc.fit(x_train.iloc[train_indices], y_train.iloc[train_indices])\n",
    "    dtc.fit(x_train.iloc[train_indices], y_train.iloc[train_indices])\n",
    "    y_pred_rf = rfc.predict(x_train.iloc[test_indices])\n",
    "    y_pred_rf = y_pred_rf >=0.5\n",
    "    y_pred_rf = y_pred_rf.astype(int)\n",
    "    y_pred_lr = lrc.predict(x_train.iloc[test_indices])\n",
    "    y_pred_dt = dtc.predict(x_train.iloc[test_indices])\n",
    "    r_dict = {'Decision_Trees':y_pred_dt, \n",
    "            'Random_Forest':y_pred_rf,\n",
    "            'LG':y_pred_lr\n",
    "           }\n",
    "    r = pd.DataFrame(data = r_dict)\n",
    "    r['Collective_Model'] = r.mode(axis = 1)[0]\n",
    "    Evaluation_Results_Lib.print_results(y_train.iloc[test_indices], r['Collective_Model'], \n",
    "                                         classifier_name = 'Collective Model')\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, results are consistent for each fold, hence the best model is robust. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
